version: '3.5'


services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.5
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    expose:
      - 2181

  kafka:
    image: confluentinc/cp-kafka:7.3.5
    container_name: kafka
    hostname: kafka
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9091:9091"
      - "9092:9092"
      - "9093:9093"
    expose:
      - 9093
      - 9092
      - 9091
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 10000
      KAFKA_LOG_RETENTION_BYTES: 204800
      KAFKA_DELETE_RETENTION_MS: 10000
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '1'
        reservations:
          memory: 2G

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.1
    container_name: kafka-ui
    ports:
      - "8080:8080"
    restart: always
    environment:
      - SERVER_PORT=8080
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
      - KAFKA_CLUSTERS_0_READONLY=true
    depends_on:
      - kafka
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  pyspark:
    build:
      context: .
      dockerfile: Dockerfile_pyspark
    container_name: pyspark-service
    ports:
      - "8006:8006"
      - "4040:4040"
    restart: always
    stdin_open: true # docker run -i
    tty: true        # docker run -t
#    user: root
    entrypoint: /bin/bash
    command: '/opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 /app/pyspark_job/pyspark_detection_vis.py'
    expose:
      - 8006
      - 4040
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'

